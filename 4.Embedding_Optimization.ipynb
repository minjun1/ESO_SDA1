{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ecd91a-5c1a-421b-af90-5394c19087be",
   "metadata": {},
   "source": [
    "# Embedding Space Optimization for DAS Data\n",
    "\n",
    "This notebook demonstrates how to **fine-tune** a pre-trained embedding \n",
    "to maximize the separation between two classes (noise vs. event). \n",
    "\n",
    "**Key Steps**:\n",
    "\n",
    "1. Load a pre-trained model and produce embeddings for your training data.  \n",
    "2. Compute the centroids (means) for event and noise embeddings.  \n",
    "3. Define a custom distance-based loss that pulls each sample toward its class centroid.  \n",
    "4. Fine-tune the embedding layer with that loss.  \n",
    "5. Classify by comparing distances to the noise/event centroids (with or without a threshold).  \n",
    "6. Evaluate performance using confusion matrix, classification report, PR/ROC curves, etc.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99c7a44-dd39-4117-9d7a-24670167beca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 23:22:45.263786: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-27 23:22:45.263866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-27 23:22:45.265391: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-27 23:22:45.275926: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# notebook cell 1: imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from my_scripts.embedding_optimization import (\n",
    "    compute_embeddings,\n",
    "    compute_class_centers,\n",
    "    fine_tune_embedding_model,\n",
    "    classify_by_distance,\n",
    "    evaluate_performance,\n",
    "    plot_pr_curve,\n",
    "    plot_roc_curve\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714746c-c2df-446a-8a21-0fe96132c441",
   "metadata": {},
   "source": [
    "## Step 1: Load Data and Pre-trained Model\n",
    "\n",
    "We assume you already have:\n",
    "- `X_train.npy`, `y_train.npy`\n",
    "- `X_test.npy`, `y_test.npy`\n",
    "- A pre-trained model saved at `saved_models/model_imb_thres40`, which has \n",
    "  an 'embedding_layer' inside.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f01b62-60e8-4acf-8260-cb5764865174",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4884, 288, 695, 1)\n",
      "y_train shape: (4884,)\n",
      "X_test  shape: (1221, 288, 695, 1)\n",
      "y_test  shape: (1221,)\n"
     ]
    }
   ],
   "source": [
    "# notebook cell 2: load data\n",
    "X_train = np.load('train_data/X_train.npy')\n",
    "y_train = np.load('train_data/y_train.npy')\n",
    "X_test  = np.load('test_data/X_test.npy')\n",
    "y_test  = np.load('test_data/y_test.npy')\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test  shape:\", X_test.shape)\n",
    "print(\"y_test  shape:\", y_test.shape)\n",
    "\n",
    "base_model_path = 'saved_models/model_imb'  # Example path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f37546f-867f-4f03-8dc4-0e04ad807280",
   "metadata": {},
   "source": [
    "## Step 2: Obtain Initial Embeddings and Compute Centroids\n",
    "\n",
    "We'll create a \"temporary\" embedding model from the pre-trained model \n",
    "and compute the centroid for noise and event classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f82039a-52f6-4200-b549-e07a57cd9ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 23:39:14.167655: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-27 23:39:17.451765: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3910325760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 174s 2s/step\n",
      "Event center shape: (128,)\n",
      "Noise center shape: (128,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "# Load entire model\n",
    "pretrained_model = load_model(base_model_path)\n",
    "# Create an embedding model that outputs from the 'embedding_layer'\n",
    "embedding_model = Model(\n",
    "    inputs=pretrained_model.input,\n",
    "    outputs=pretrained_model.get_layer('embedding_layer').output\n",
    ")\n",
    "\n",
    "# Produce embeddings for training data\n",
    "embeddings_train = compute_embeddings(embedding_model, X_train, batch_size=64)\n",
    "# Compute centroids\n",
    "event_center, noise_center = compute_class_centers(embeddings_train, y_train)\n",
    "\n",
    "print(\"Event center shape:\", event_center.shape)\n",
    "print(\"Noise center shape:\", noise_center.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d50989-ffd2-49c5-b6f4-4564c6ec2a56",
   "metadata": {},
   "source": [
    "## Step 3: Fine-Tune the Embedding Model with Distance Loss\n",
    "\n",
    "We'll optimize the embedding space to pull each sample closer \n",
    "to its respective class centroid. We define a margin (e.g., 10.0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31aa653a-75e6-48aa-b5d4-1782758d0cef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fine_tune_embedding_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fine_tuned_model, history \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune_embedding_model\u001b[49m(\n\u001b[1;32m      2\u001b[0m     base_model_path\u001b[38;5;241m=\u001b[39mbase_model_path,\n\u001b[1;32m      3\u001b[0m     X_train\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[1;32m      4\u001b[0m     y_train\u001b[38;5;241m=\u001b[39my_train,\n\u001b[1;32m      5\u001b[0m     event_center\u001b[38;5;241m=\u001b[39mevent_center,\n\u001b[1;32m      6\u001b[0m     noise_center\u001b[38;5;241m=\u001b[39mnoise_center,\n\u001b[1;32m      7\u001b[0m     distance_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.0\u001b[39m,\n\u001b[1;32m      8\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      9\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,  \u001b[38;5;66;03m# For demonstration, you can go higher (e.g. 500)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     checkpoint_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_models/optimize/model_epoch_\u001b[39m\u001b[38;5;132;01m{epoch:03d}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fine_tune_embedding_model' is not defined"
     ]
    }
   ],
   "source": [
    "fine_tuned_model, history = fine_tune_embedding_model(\n",
    "    base_model_path=base_model_path,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    event_center=event_center,\n",
    "    noise_center=noise_center,\n",
    "    distance_margin=10.0,\n",
    "    batch_size=64,\n",
    "    epochs=50,  # For demonstration, you can go higher (e.g. 500)\n",
    "    checkpoint_path='saved_models/optimize/model_epoch_{epoch:03d}.h5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c97871-9ad3-4e4e-961b-cdfa900e10a8",
   "metadata": {},
   "source": [
    "## Step 4: Use the Fine-Tuned Model to Generate New Embeddings\n",
    "\n",
    "Now we get improved embeddings for both train and test sets \n",
    "using the fine-tuned embedding model. We'll do a distance-based classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d958f70e-b003-4ca0-8ae6-daeab1fb1096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings_train_up \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_embeddings\u001b[49m(fine_tuned_model, X_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m      2\u001b[0m embeddings_test_up  \u001b[38;5;241m=\u001b[39m compute_embeddings(fine_tuned_model, X_test,  batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# We'll still use the same (event_center, noise_center) for classification, \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# or optionally recompute them from updated train embeddings:\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings_train_up = compute_embeddings(fine_tuned_model, X_train, batch_size=64)\n",
    "embeddings_test_up  = compute_embeddings(fine_tuned_model, X_test,  batch_size=64)\n",
    "\n",
    "# We'll still use the same (event_center, noise_center) for classification, \n",
    "# or optionally recompute them from updated train embeddings:\n",
    "updated_event_center, updated_noise_center = compute_class_centers(embeddings_train_up, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514fa219-c8a2-49b6-bf17-e53a1b15e2f9",
   "metadata": {},
   "source": [
    "## Step 5: Decide on a Distance Threshold and Classify\n",
    "\n",
    "Here we illustrate **two** ways to classify:\n",
    "\n",
    "1. **Min-Distance Rule**: Classify as event if distance_to_event < distance_to_noise.  \n",
    "2. **Noise-Center Threshold**: If distance_to_noise > some threshold => event.  \n",
    "\n",
    "We'll demonstrate the second approach, as shown in the sample code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b2c410-5068-4652-81b5-0bf4088fdf9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classify_by_distance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# notebook cell 6: distance-based classification\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 1) Classify with no explicit threshold => whichever center is closer\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_pred_min_dist, dist_event, dist_noise \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_by_distance\u001b[49m(\n\u001b[1;32m      5\u001b[0m     embeddings_test_up, \n\u001b[1;32m      6\u001b[0m     updated_event_center, \n\u001b[1;32m      7\u001b[0m     updated_noise_center, \n\u001b[1;32m      8\u001b[0m     threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m evaluate_performance(y_test, y_pred_min_dist, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMin-Distance Classification\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 2) Classify by threshold on noise distance:\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#    if distance_to_noise > threshold => event\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# We can pick threshold from e.g. the 99th percentile of noise distances in training set\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classify_by_distance' is not defined"
     ]
    }
   ],
   "source": [
    "# notebook cell 6: distance-based classification\n",
    "\n",
    "# 1) Classify with no explicit threshold => whichever center is closer\n",
    "y_pred_min_dist, dist_event, dist_noise = classify_by_distance(\n",
    "    embeddings_test_up, \n",
    "    updated_event_center, \n",
    "    updated_noise_center, \n",
    "    threshold=None\n",
    ")\n",
    "\n",
    "evaluate_performance(y_test, y_pred_min_dist, title=\"Min-Distance Classification\")\n",
    "\n",
    "# 2) Classify by threshold on noise distance:\n",
    "#    if distance_to_noise > threshold => event\n",
    "# We can pick threshold from e.g. the 99th percentile of noise distances in training set\n",
    "noise_dist_train = dist_noise[:len(X_train)]  # If train+test are in one array, adjust as needed\n",
    "threshold = np.percentile(noise_dist_train, 99.0)\n",
    "\n",
    "y_pred_thresh, dist_event_test, dist_noise_test = classify_by_distance(\n",
    "    embeddings_test_up, \n",
    "    updated_event_center, \n",
    "    updated_noise_center, \n",
    "    threshold=threshold\n",
    ")\n",
    "evaluate_performance(y_test, y_pred_thresh, title=\"Threshold Classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc2503-4f3f-4300-9de6-f2d537b5a15e",
   "metadata": {},
   "source": [
    "## Step 6: Precision-Recall and ROC Curves\n",
    "\n",
    "We'll treat `distance_to_event` or `distance_to_noise` as a \"score.\"  \n",
    "For PR/ROC, recall that smaller distance => more event-like. We'll invert (multiply by -1) if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e4eff1-9404-418b-a462-eb3ef7d89b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_pr_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# We can choose dist_noise_test for example\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pr_auc \u001b[38;5;241m=\u001b[39m \u001b[43mplot_pr_curve\u001b[49m(y_test, dist_noise_test, label_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistance to Noise Center\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m plot_roc_curve(y_test, dist_noise_test, label_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistance to Noise Center\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPR-AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpr_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ROC-AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_pr_curve' is not defined"
     ]
    }
   ],
   "source": [
    "# We can choose dist_noise_test for example\n",
    "pr_auc = plot_pr_curve(y_test, dist_noise_test, label_name='Distance to Noise Center')\n",
    "roc_auc = plot_roc_curve(y_test, dist_noise_test, label_name='Distance to Noise Center')\n",
    "print(f\"PR-AUC: {pr_auc:.3f}, ROC-AUC: {roc_auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71daaa8d-98b7-4d1c-92ea-422c4410dc29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-15:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
